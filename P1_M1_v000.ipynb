{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P1_M1_partialsolution.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM+yeKQYM8wG+9DEa/wpAz9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qkM1YpNmzd9C"},"source":["# Milestone 1: Implement Non Negative Matrix Factorization from Scratch"]},{"cell_type":"markdown","metadata":{"id":"6MBte9fn0L6a"},"source":["## Module Imports"]},{"cell_type":"code","metadata":{"id":"Ob32FEl40RLB"},"source":["# Required module imports\n","import numpy as np\n","from IPython.display import HTML, display\n","import numpy.linalg as LA"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u6GfsyoB0iTj"},"source":["## Helper Methods\n","\n","Helper Methods are provided to:\n","* create a document matrix \n","* print the output of the NMF in nice tables"]},{"cell_type":"code","metadata":{"id":"BtK31FBIyndK"},"source":["\n","def simple_document_processor(documents_list, words_to_remove = ['i', 'use', 'in', 'is', 'a', 'for']):\n","  \"\"\" Remove stop words, convert to lowercase and return both a Matrix with Document to Word counts and a Vocabularly for the dataset  \"\"\"\n","  processed_docs = []\n","  for doc in documents_list:\n","    # make text document into a list of words\n","    words = doc.split(\" \")\n","    # convert all words to lowercase\n","    words = [word.lower() for word in words]\n","    # remove all words that are provided in the words_to_remove list\n","    new_doc = [word for word in words if not word in words_to_remove]\n","    processed_docs.append(new_doc)\n","\n","  # Make a list of unique words from all the documents (known as a vocabulary)\n","  vocab = [j for i in processed_docs for j in i]\n","  unique_vocab=list(set(vocab))\n","\n","  # Replace each word in a document with its unique id from the vocabulary\n","  doc_vocabindex_list = []\n","  for doc in processed_docs:\n","    numeric_doc = [0] * len(unique_vocab)\n","    for word in doc:\n","      numeric_doc[unique_vocab.index(word)] = 1\n","    doc_vocabindex_list.append(numeric_doc)\n","  # Convert the list of word lists to a numpy Matrix\n","  doc_word_matrix = np.array(doc_vocabindex_list)\n","\n","  # return the Matrix and Vocab list\n","  return (doc_word_matrix, unique_vocab)\n","\n","def display_matrix_as_table(matrix, column_headers, row_headers, first_cell_text):\n","  \"\"\" Pretty print a Matrix as a table  \"\"\"\n","  list_of_rows = matrix.tolist()\n","  html = \"<table border='1' style='border-spacing:0px'>\"\n","  html += \"<tr>\"\n","  html += \"<td style='padding:5px'><h4>%s</h4></td>\"%(first_cell_text)\n","  for header in column_headers:\n","    html += \"<td style='padding:5px'><h4>%s</h4></td>\"%(header)\n","\n","  html += \"</tr>\"\n","  for rownum, row in enumerate(list_of_rows):\n","    html += \"<tr>\"\n","    html += \"<td style='padding:5px'><h4>%s</h4></td>\"%(row_headers[rownum])\n","    for field in row:\n","      html += \"<td style='padding:5px;text-align:center'><h3>%.2f</h3></td>\"%(field)\n","    html += \"</tr>\"\n","\n","  html += \"</table>\" \n","  html += \"<br />\" \n","  display(HTML(html))     \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FZNuW8YU1EIR"},"source":["## Convert a List of strings to a Document to Word Matrix\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"DVTwBJSk1Fp5","executionInfo":{"status":"ok","timestamp":1627035519113,"user_tz":-600,"elapsed":291,"user":{"displayName":"Aneesha Bakharia","photoUrl":"","userId":"12769987994699658367"}},"outputId":"d4336421-0e15-4797-da7e-1c68a9b5cc04"},"source":["documents = [\n","             \"I use statistics in Data Science\",\n","             \"I use linear algebra in Data Science\",\n","             \"I program in python\",\n","             \"Python is a great language to program with\",\n","             'I use python for Data Science',\n","             \"I program linear algebra in python\"\n","]\n","words_to_remove = ['i', 'use', 'in', 'is', 'a', 'for', 'to', 'with']\n","\n","doc_word_matrix, unique_vocab = simple_document_processor(documents, words_to_remove)\n","\n","display_matrix_as_table(doc_word_matrix, unique_vocab, documents, 'Documents')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border='1' style='border-spacing:0px'><tr><td style='padding:5px'><h4>Documents</h4></td><td style='padding:5px'><h4>algebra</h4></td><td style='padding:5px'><h4>data</h4></td><td style='padding:5px'><h4>science</h4></td><td style='padding:5px'><h4>program</h4></td><td style='padding:5px'><h4>language</h4></td><td style='padding:5px'><h4>linear</h4></td><td style='padding:5px'><h4>great</h4></td><td style='padding:5px'><h4>python</h4></td><td style='padding:5px'><h4>statistics</h4></td></tr><tr><td style='padding:5px'><h4>I use statistics in Data Science</h4></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td></tr><tr><td style='padding:5px'><h4>I use linear algebra in Data Science</h4></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td></tr><tr><td style='padding:5px'><h4>I program in python</h4></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td></tr><tr><td style='padding:5px'><h4>Python is a great language to program with</h4></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td></tr><tr><td style='padding:5px'><h4>I use python for Data Science</h4></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td></tr><tr><td style='padding:5px'><h4>I program linear algebra in python</h4></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td><td style='padding:5px;text-align:center'><h3>1.00</h3></td><td style='padding:5px;text-align:center'><h3>0.00</h3></td></tr></table><br />"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"71DTh3RY08pm"},"source":["## The NMF Class\n","\n","Please complete the follwing steps in the code below:\n","\n","* STEP 2: Initialise W and H with random values\n","* STEP 3: Implement the update rules for W and H\n","* STEP 4: Implement the perform_factorization() method\n","* STEP 5: Run NMF and review the resulting W and H matrices\n","* (CHALLENGE) STEP 7: Implement Early Stopping"]},{"cell_type":"code","metadata":{"id":"oQwOQ-KYlNLX"},"source":["np.set_printoptions(suppress=True)\n","\n","class NMF():\n","\n","  def __init__(self, A, no_topics=2, **kwargs):\n","\n","    self.A = A\n","    self._no_topics = no_topics\n","\n","    self._no_documents, self._no_words = self.A.shape\n","\n","    self._epsilon = 2**-8\n","\n","  def calc_reconstruction_error(self):\n","    \"\"\" Euclidean error between X and W*H using Frobenious norm \"\"\"\n","\n","    if hasattr(self,'H') and hasattr(self,'W'):\n","      error = LA.norm(self.A - np.dot(self.W, self.H))\n","    else:\n","      error = None\n","\n","    return error\n","\n","  def randomize_wh(self):\n","    \"\"\" Initalize W and H with random values between 0 and 1.\"\"\"\n","    # Todo - STEP 2 -  Initialise W and H with random values\n","    self.W = \n","    self.H = \n","\n","  def update_h(self):\n","    # Todo - STEP 3: Implement the update rules for W and H\n","    # H = H .* (W'A) ./ (W'WH + epsilon)\n","    self.H = \n","\n","  def update_w(self):\n","    # Todo - STEP 3: Implement the update rules for W and H\n","    # W = W .* (AH' ) ./ (WHH' + epsilon)\n","    self.W =\n","\n","  def perform_factorization(self, max_iter=1000, tolerance=0.001):\n","    \n","    #Todo - STEP 4: Implement the perform_factorization() method\n","\n","\n","    #Todo - CHALLENGE) STEP 7: Implement Early Stopping\n","    for i in range(1, max_iter):\n","\n","   \n","    return (self.W, self.H, self.reconstruction_error, number_of_iterations)\n","   \n","max_iter = 100\n","nmf = NMF(doc_word_matrix, no_topics=2)\n","W, H, reconstruction_error, number_of_iterations = nmf.perform_factorization(max_iter)\n","\n","display_matrix_as_table(W, ['Topic 1', 'Topic 2'], documents, 'Documents')\n","\n","display_matrix_as_table(H, unique_vocab, ['Topic 1', 'Topic 2'], 'Topics')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXlv_AMv2si2"},"source":["## Plot the Reconstruction Error \n","\n","The code below implements:\n"," * STEP 5: Plot the reconstruction error]"]},{"cell_type":"code","metadata":{"id":"3WD8POJC_HxL"},"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12,7))\n","plt.plot(range(number_of_iterations), reconstruction_error[0:number_of_iterations])  \n","\n","plt.xlabel(\"Number of Iterations\")\n","plt.ylabel(\"Reconstruction Error\")\n","plt.title(\"Convergence of NMF\")\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]}]}